{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "resnet_model_train_and_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElMq_pKxquoI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary\n",
        "import time\n",
        "import os \n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 32\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layer1 = self._make_layer(block, 32, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 64, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 128, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 256, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "def project1_model():\n",
        "    return ResNet(BasicBlock, [8, 6, 4, 3])\n",
        "\n",
        "class ResNetParams:\n",
        "   \"\"\"\n",
        "    A class to pass the hyperparameters to the model\n",
        "   \"\"\"\n",
        "   def __init__(self, arch='Model 1' ,epochs=200, start_epoch=0, batch_size=128, lr=0.1, momentum=0.9, weight_decay=1e-4, print_freq=50,\n",
        "                save_dir='save_temporary_checkpoints', save_every=10):\n",
        "        self.save_every = save_every #Saves checkpoints at every specified number of epochs\n",
        "        self.save_dir = save_dir #The directory used to save the trained models\n",
        "        self.print_freq = print_freq #print frequency \n",
        "        self.weight_decay = weight_decay #Weight decay for SGD\n",
        "        self.momentum = momentum #Momentum for SGD\n",
        "        self.lr = lr #Learning Rate\n",
        "        self.batch_size = batch_size #Batch Size for each epoch \n",
        "        self.start_epoch = start_epoch #Starting Epoch\n",
        "        self.epochs = epochs #Total Epochs\n",
        "        self.arch = arch #ResNet model name\n",
        "\n",
        "def run_epochs():\n",
        "    global args, best_precision\n",
        "    #Check if the save_dir exists or not\n",
        "    if not os.path.exists(args.save_dir):\n",
        "        os.makedirs(args.save_dir)\n",
        "    #Loading the model \n",
        "    model = project1_model()\n",
        "    model.cuda()\n",
        "\n",
        "    #Defining the Loss Function\n",
        "    loss_func = nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    #Defining the Optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
        "                                momentum=args.momentum,\n",
        "                                weight_decay=args.weight_decay)\n",
        "    \n",
        "    #Defining the Learning Rate Scheduler\n",
        "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                                                        milestones=[100, 150], last_epoch=args.start_epoch - 1)\n",
        "\n",
        "    for epoch in range(args.start_epoch, args.epochs):\n",
        "        #Train for one epoch\n",
        "        print('Training model: {}'.format(args.arch))\n",
        "        print('Current Learning Rate {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
        "        train(train_loader, model, loss_func, optimizer, epoch)\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        #Test for one epoch\n",
        "        precision = validate(val_loader, model, loss_func)\n",
        "\n",
        "        #Save the best precision and make a checkpoint\n",
        "        is_best = precision > best_precision\n",
        "        best_precision = max(precision, best_precision)\n",
        "        if epoch > 0 and epoch % args.save_every == 0:\n",
        "            torch.save(model.state_dict(), os.path.join(args.save_dir, 'project1_model_checkpoint.th'))\n",
        "        if is_best:\n",
        "            torch.save(model.state_dict(), os.path.join(args.save_dir, 'project1_model.th'))\n",
        "    return best_precision\n",
        "\n",
        "class KeepAverages(object):\n",
        "    #Computes and stores the average along with the current value\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    #Computes the top 1 precision\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res\n",
        "\n",
        "def validate(val_loader, model, loss_func):\n",
        "    #Run an Evaluation\n",
        "    batch_time = KeepAverages()\n",
        "    losses = KeepAverages()\n",
        "    top1 = KeepAverages()\n",
        "\n",
        "    #Switch to Evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in enumerate(val_loader):\n",
        "            target = target.cuda()\n",
        "            input_var = input.cuda()\n",
        "            target_var = target.cuda()\n",
        "\n",
        "            #Compute the output of the Model and calculate the Loss\n",
        "            output = model(input_var)\n",
        "            loss = loss_func(output, target_var)\n",
        "            output = output.float()\n",
        "            loss = loss.float()\n",
        "\n",
        "            #Measure the Loss and Update it \n",
        "            precision = accuracy(output.data, target)[0]\n",
        "            losses.update(loss.item(), input.size(0))\n",
        "            top1.update(precision.item(), input.size(0))\n",
        "\n",
        "            #Measure the elapsed time\n",
        "            batch_time.update(time.time() - end)\n",
        "            end = time.time()\n",
        "\n",
        "\n",
        "    print('Test Accuracy\\t  Top Precision: {top1.avg:.3f} (Error: {error:.3f} )\\n'\n",
        "          .format(top1=top1,error=100-top1.avg))\n",
        "    val_losses.append(100-top1.avg)\n",
        "    return top1.avg\n",
        "\n",
        "def train(train_loader, model, loss_func, optimizer, epoch):\n",
        "    #Run one training epoch\n",
        "\n",
        "    batch_time = KeepAverages()\n",
        "    data_time = KeepAverages()\n",
        "    losses = KeepAverages()\n",
        "    top1 = KeepAverages()\n",
        "\n",
        "    #Switch to Train mode\n",
        "    model.train()\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # Measure the data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        target = target.cuda()\n",
        "        input_var = input.cuda()\n",
        "        target_var = target\n",
        "\n",
        "        #Compute the output and the Loss\n",
        "        output = model(input_var)\n",
        "        loss = loss_func(output, target_var)\n",
        "\n",
        "        #Compute the Gradient and do an SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        output = output.float()\n",
        "        loss = loss.float()\n",
        "        \n",
        "        #Measure the accuracy and record the loss\n",
        "        precision = accuracy(output.data, target)[0]\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(precision.item(), input.size(0))\n",
        "\n",
        "        #Measure the Elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % args.print_freq == 0:\n",
        "            print('Epoch: No: [{0}] Batches: [{1}/{2}]\\t'\n",
        "                  'Loss: {loss.val:.4f} (Average: {loss.avg:.4f})\\t'\n",
        "                  'Precision: {top1.val:.3f} (Average: {top1.avg:.3f})'.format(\n",
        "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
        "                      data_time=data_time, loss=losses, top1=top1))\n",
        "    train_losses.append(100-top1.val)\n",
        "\n",
        "def imshow(img):\n",
        "  #Function to show an image\n",
        "  %matplotlib inline\n",
        "  %config InlineBackend.figure_format = 'retina'\n",
        "  img = img / 2 + 0.5     # un - Normalize\n",
        "  npimg = img.numpy()\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "\n",
        "args=ResNetParams()\n",
        "val_losses = []\n",
        "train_losses = []\n",
        "\n",
        "#Load the data\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                     std=[0.229, 0.224, 0.225])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                 datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
        "                 transforms.RandomHorizontalFlip(),\n",
        "                 transforms.RandomCrop(32, 4),\n",
        "                 transforms.ToTensor(),\n",
        "                 normalize,\n",
        "                 ]), download=True),\n",
        "                 batch_size=128, shuffle=True,\n",
        "                 num_workers=4, pin_memory=True)\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "               datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
        "               transforms.ToTensor(),\n",
        "               normalize,\n",
        "               ])),\n",
        "               batch_size=128, shuffle=False,\n",
        "               num_workers=4, pin_memory=True)\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "'''  \n",
        "#Obtaining some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "plt.figure(figsize=(20,10)) \n",
        "\n",
        "#Showing the images\n",
        "imshow(torchvision.utils.make_grid(images[0:8,:,:]))\n",
        "  \n",
        "#Printing their labels\n",
        "print(' '.join('%15s' % classes[labels[j]] for j in range(3)))\n",
        "\n",
        "'''\n",
        "\n",
        "\n",
        "#Load the device and move the model to the device (GPU/CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "model = project1_model().to(device)\n",
        "\n",
        "#Obtain the summary of the loaded data\n",
        "summary(model, (3,32,32))\n",
        "best_precision = 0\n",
        "\n",
        "#Run the epochs\n",
        "best_precision = run_epochs()\n",
        "print('The lowest error from model: {} after {} epochs is {error:.3f}'.format(args.arch,args.epochs, error=100-best_precision))\n",
        "model_save_name = 'project1_model.pt'\n",
        "#path = F\"/content/gdrive/My Drive/{model_save_name}\" \n",
        "\n",
        "#Saving the generated model and testing its loading\n",
        "path = model_save_name\n",
        "torch.save(model.state_dict(), path) \n",
        "model_path = path\n",
        "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)\n",
        "\n",
        "#Plotting the model\n",
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.plot(val_losses,label=\"Val\")\n",
        "plt.plot(train_losses,label=\"Train\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('plot_graph.png')"
      ]
    }
  ]
}
